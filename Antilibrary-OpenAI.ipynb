{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d73a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "\n",
    "!pip install pandoc langchain gradio chromadb tiktoken clean-text\n",
    "!pip install \"unstructured[local-inference]\"\n",
    "!pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
    "!pip install layoutparser pypdf unidecode\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandoc\n",
    "from io import StringIO\n",
    "import gradio as gr\n",
    "import re\n",
    "import time\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from langchain.document_loaders import UnstructuredEPubLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "from html.parser import HTMLParser\n",
    "import chromadb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d5439ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"your openai api key goes here\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad5d14f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1081, which is longer than the specified 1000\n",
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7896\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7896/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def examinelibrary():\n",
    "    # Define the extensions we're looking for\n",
    "    extensions = ['txt', 'md', 'pdf', 'doc', 'docx']\n",
    "\n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "\n",
    "    # Scan the directory\n",
    "    for extension in extensions:\n",
    "        counter += len(glob.glob(\"/books/*.\" + extension))\n",
    "        \n",
    "    # Initialize library as dict and load documents into it\n",
    "    library = {}\n",
    "    for extension in extensions:\n",
    "        for file_name in glob.glob(\"books/*.\" + extension):\n",
    "            content = \"\"\n",
    "            if extension in ['txt', 'md']:\n",
    "                loader = TextLoader(file_name)\n",
    "            elif extension in ['doc', 'docx']:\n",
    "                loader = UnstructuredWordDocumentLoader(file_name) \n",
    "            elif extension == 'pdf':\n",
    "                loader = PyPDFLoader(file_name)\n",
    "            elif extension == 'epub':  \n",
    "                loader = UnstructuredEPubLoader(file_name) \n",
    "        # Load the contents of the file        \n",
    "        documents = loader.load()\n",
    "        # Add the file and its contents to the library\n",
    "        library[file_name] = documents\n",
    "        \n",
    "    # Display the count of files detected   \n",
    "    return(library, counter)\n",
    "\n",
    "# Split the texts in the library into chunks\n",
    "def processtext(library):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = []\n",
    "    for file_name in library:\n",
    "          texts += text_splitter.split_documents(library[file_name])\n",
    "    return texts\n",
    "\n",
    "# Produce a librarian (database of embedded texts)\n",
    "def prodlibrarian():\n",
    "    library,counter = examinelibrary()\n",
    "    texts = processtext(library)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = Chroma.from_documents(texts, embeddings)\n",
    "    return db\n",
    "\n",
    "# Call prodlibrarian on startup\n",
    "db = prodlibrarian()\n",
    "\n",
    "# Initialize language model and qa chain\n",
    "llm = OpenAI(temperature=0)\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# Call prodlibrarian and display progress\n",
    "def scan(progress=gr.Progress()):\n",
    "    progress(0.2, desc=\"Examining /books folder ...\")\n",
    "    time.sleep(1)\n",
    "    progress(0.4, desc=\"Counting documents ...\")\n",
    "    time.sleep(1.5)\n",
    "    progress(0.6, desc=\"Generating embeddings ...\")\n",
    "    time.sleep(1.5)\n",
    "    db = prodlibrarian()\n",
    "    return \"Librarian found and embedded \" + str(counter) + \" documents.\"\n",
    "\n",
    "# Main query code.\n",
    "def ask(query, progress=gr.Progress()):\n",
    "    progress(0.1, desc=\"Scanning embedded documents for matches ...\")\n",
    "    time.sleep(1)\n",
    "    progress(0.2, desc=\"Assembling request...\")\n",
    "    time.sleep(1.5)\n",
    "    progress(0.4, desc=\"Appending citations and metadata ...\")\n",
    "    time.sleep(1.5)\n",
    "    progress(0.5, desc=\"Talking to LLM for answers ...\")\n",
    "    time.sleep(1.5)\n",
    "    #generate docs which are texts relevant to the query\n",
    "    docs = db.similarity_search(query) \n",
    "    #some muckwork to log sources\n",
    "    x = 0\n",
    "    citations = \"\"\n",
    "    for x in range(len(docs)): \n",
    "        citations += docs[x].metadata['source'] + \" in page: \" + str(docs[x].metadata['page'])  + \"\\n\"\n",
    "        \n",
    "    #calls llm with the query and relevant docs in hand and returns both the response and the sources    \n",
    "    librarianoutput = f\"{chain.run(input_documents=docs, question=query)}\"\n",
    "    output = \"Answer: \\n\" + librarianoutput + \"\\n\\nI found this in: \\n\" +  str(citations) \n",
    "    return (output)\n",
    "\n",
    "#Gradio UI\n",
    "with gr.Blocks() as app:\n",
    "    \n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"# Welcome to your antilibrary!\")\n",
    "        scan_btn = gr.Button(\"Scan the library again.\")\n",
    "        \n",
    "    query = gr.Textbox(label=\"What can I help you find?\")\n",
    "    output = gr.Textbox(label=\"Response:\")\n",
    "    ask_btn = gr.Button(\"Ask Librarian\")\n",
    "    \n",
    "    ask_btn.click(fn=ask, inputs=query, outputs=output)\n",
    "    scan_btn.click(fn=scan, outputs=output)\n",
    "    gr.Markdown(\"*...a private library is not an ego-boosting appendage but a research tool. The library should contain as much of what you do not know ... You will accumulate more knowledge and more books as you grow older, and the growing number of unread books on the shelves will look at you menacingly. Indeed, the more you know, the larger the rows of unread books. Let us call this collection of unread books an antilibrary.* \\n - Nassim Nicholas Taleb, The Black Swan\")\n",
    "app.queue(concurrency_count=10).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bookwormenv] *",
   "language": "python",
   "name": "conda-env-bookwormenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
